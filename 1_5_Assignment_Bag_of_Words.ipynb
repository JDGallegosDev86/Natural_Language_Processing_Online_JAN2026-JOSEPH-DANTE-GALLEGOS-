{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7ebe4a-d005-4467-9283-a2e97ea700a0",
   "metadata": {},
   "source": [
    "# 1.5 Assignment — Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470c1e4-693b-45f6-8d77-07597494f3fa",
   "metadata": {},
   "source": [
    "# Will import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cf8af8c-289a-4b17-a489-cb028e65cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b830e9-a9ff-4d97-a097-a96c4cf13f10",
   "metadata": {},
   "source": [
    "# Used to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04b143fa-40e5-45b6-b2d8-b005c5481c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from: C:\\Users\\MasterDanteDev86\\Downloads\\CAP355-O Natural Language Processing - Online\\W1\\NLP\\data\\ham-spam.csv\n",
      "Shape: (5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative path\n",
    "relative_path = Path(\"data\") / \"ham-spam.csv\"\n",
    "\n",
    "# Absolute path (If needed)\n",
    "absolute_path = Path(r\"C:\\Users\\MasterDanteDev86\\Downloads\\CAP355-O Natural Language Processing - Online\\W1\\NLP\\data\\ham-spam.csv\")\n",
    "\n",
    "if relative_path.exists():\n",
    "    data_path = relative_path\n",
    "else:\n",
    "    data_path = absolute_path\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded from:\", data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1272a-92e5-4dc8-9aee-8e796aee3dfb",
   "metadata": {},
   "source": [
    "# Will inspect dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a21d7d9-961e-4337-89bd-2b838c4c00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['label', 'text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Will detect label/text columns\n",
    "lower_cols = [c.lower() for c in df.columns]\n",
    "\n",
    "label_col = None\n",
    "text_col = None\n",
    "\n",
    "# The common guesses\n",
    "for c in df.columns:\n",
    "    cl = c.lower()\n",
    "    if label_col is None and cl in [\"label\", \"category\", \"type\", \"class\"]:\n",
    "        label_col = c\n",
    "    if text_col is None and cl in [\"message\", \"text\", \"sms\", \"body\", \"content\"]:\n",
    "        text_col = c\n",
    "\n",
    "# \"Not Found, will fall back to first two columns\n",
    "if label_col is None or text_col is None:\n",
    "    if df.shape[1] >= 2:\n",
    "        label_col = df.columns[0]\n",
    "        text_col = df.columns[1]\n",
    "\n",
    "df = df[[label_col, text_col]].copy()\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df[\"label\"] = df[\"label\"].astype(str).str.lower().str.strip()\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350a9c8-f34c-474e-8833-8db13869eec2",
   "metadata": {},
   "source": [
    "# The class distribution and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9c04651-433b-4b42-ad36-eb9d35e47ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "A few example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>ham</td>\n",
       "      <td>Funny fact Nobody teaches volcanoes 2 erupt, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>ham</td>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>spam</td>\n",
       "      <td>We know someone who you know that fancies you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>ham</td>\n",
       "      <td>Only if you promise your getting out as SOON a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>spam</td>\n",
       "      <td>Congratulations ur awarded either å£500 of CD ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "3245   ham  Funny fact Nobody teaches volcanoes 2 erupt, t...\n",
       "944    ham  I sent my scores to sophas and i had to do sec...\n",
       "1044  spam  We know someone who you know that fancies you....\n",
       "2484   ham  Only if you promise your getting out as SOON a...\n",
       "812   spam  Congratulations ur awarded either å£500 of CD ..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Class counts:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "print(\"\\nA few example rows:\")\n",
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a75e2e-10c9-4a98-b02c-0b66a0f1e8de",
   "metadata": {},
   "source": [
    "# Used to create text cleaning function\n",
    "\n",
    "The function:\n",
    "\n",
    "1. Will convert text to lowercase\n",
    "\n",
    "2. Will remove punctuation\n",
    "\n",
    "3. Will remove stopwords\n",
    "\n",
    "The function will be applied to every message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0759435-f78d-4aaf-bbe5-0124f66fe3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "def clean_text(message):\n",
    "    # Lowercase\n",
    "    msg = message.lower()\n",
    "\n",
    "    # Removes punctuation\n",
    "    msg = msg.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Will remove the extra whitespace, and will keep only: (words/numbers/spaces)\n",
    "    msg = re.sub(r\"\\s+\", \" \", msg).strip()\n",
    "\n",
    "    # Removes stopwords\n",
    "    words = msg.split()\n",
    "    kept = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            kept.append(w)\n",
    "\n",
    "    return \" \".join(kept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1d674-eabb-4422-8d47-dfceee7279ba",
   "metadata": {},
   "source": [
    "# Will apply cleaning to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd4c065c-f8c2-4dac-b989-832c289710e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ham</td>\n",
       "      <td>You will be in the place of that man</td>\n",
       "      <td>place man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\Si.como no?!listened2the plaid album-quite gd...</td>\n",
       "      <td>sicomo nolistened2the plaid albumquite gdthe n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>ham</td>\n",
       "      <td>K da:)how many page you want?</td>\n",
       "      <td>k dahow page want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ham</td>\n",
       "      <td>I asked you to call him now ok</td>\n",
       "      <td>asked ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>ham</td>\n",
       "      <td>Small problem in auction:)punj now asking tiwary</td>\n",
       "      <td>small problem auctionpunj asking tiwary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "83     ham               You will be in the place of that man   \n",
       "2235   ham  \\Si.como no?!listened2the plaid album-quite gd...   \n",
       "2746   ham                      K da:)how many page you want?   \n",
       "246    ham                     I asked you to call him now ok   \n",
       "3120   ham   Small problem in auction:)punj now asking tiwary   \n",
       "\n",
       "                                             clean_text  \n",
       "83                                            place man  \n",
       "2235  sicomo nolistened2the plaid albumquite gdthe n...  \n",
       "2746                                  k dahow page want  \n",
       "246                                            asked ok  \n",
       "3120            small problem auctionpunj asking tiwary  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# This will show the before and after for a few rows\n",
    "mini = df.sample(5, random_state=7)[[\"label\", \"text\", \"clean_text\"]]\n",
    "mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986394b-7aa9-4fd3-9c46-e2e030ca1a71",
   "metadata": {},
   "source": [
    "# Convert text to Bag-of-Words features (CountVectorizer)\n",
    "\n",
    "CountVectorizer to turn the cleaned messages into a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f9fd0de-c7f9-4656-a40f-2cbde1b627f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (5572, 9229)\n",
      "Example vocabulary size: 9229\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Example vocabulary size:\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110d233-9801-46ab-af5d-0cbc8de545db",
   "metadata": {},
   "source": [
    "# Train and test split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10252959-100d-49c2-8a9b-cade304f91e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4457\n",
      "Test size: 1115\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7c580-f4f2-4c34-a969-d3bf3eb83b93",
   "metadata": {},
   "source": [
    "# Train (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47e45889-d350-4441-b79b-092b5af8f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9730941704035875\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "\n",
    "nb_acc = accuracy_score(y_test, nb_pred)\n",
    "print(\"Naive Bayes Accuracy:\", nb_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c3f61-4477-4bc2-b778-0dfa290c85dd",
   "metadata": {},
   "source": [
    "# Evaluatioin with training model (Naive Bayes)\n",
    "\n",
    "We can see the following:\n",
    "\n",
    "1. The Accuracy\n",
    "\n",
    "2. The confusion matrix\n",
    "\n",
    "3. The classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1ccb7e0-13ee-4edd-aef2-6d5e692b1c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Naive Bayes):\n",
      "[[946  20]\n",
      " [ 10 139]]\n",
      "\n",
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.98       966\n",
      "        spam       0.87      0.93      0.90       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.96      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix (Naive Bayes):\")\n",
    "print(confusion_matrix(y_test, nb_pred))\n",
    "\n",
    "print(\"\\nClassification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dfc18-00cd-444c-aeb9-dc275cc3a675",
   "metadata": {},
   "source": [
    "# Testing with 3 of my own messages\n",
    "\n",
    "Will predict my custom messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5a954f90-3e74-4be1-be6a-b75cb30d92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message: Good Evening, are we still meeting for the class lecture tomorrow at 7:15am?\n",
      "Cleaned : good evening meeting class lecture tomorrow 715am\n",
      "Prediction: ham\n",
      "Probabilities: {'ham': 0.9999994471820166, 'spam': 5.528179854261926e-07}\n",
      "\n",
      "Message: CONGRATS!! You won $1 million in cash with Publishers Clearing House. Click the link to claim your prize now!!!\n",
      "Cleaned : congrats won 1 million cash publishers clearing house click link claim prize\n",
      "Prediction: spam\n",
      "Probabilities: {'ham': 4.4760394749083895e-08, 'spam': 0.999999955239603}\n",
      "\n",
      "Message: Reminder: your vehicle appointment is scheduled for Saturday at 7am with Hyundai Service. Reply YES to confirm.\n",
      "Cleaned : reminder vehicle appointment scheduled saturday 7am hyundai service reply yes confirm\n",
      "Prediction: spam\n",
      "Probabilities: {'ham': 0.09533544497911167, 'spam': 0.9046645550208934}\n"
     ]
    }
   ],
   "source": [
    "my_messages = [\n",
    "    \"Good Evening, are we still meeting for the class lecture tomorrow at 7:15am?\",\n",
    "    \"CONGRATS!! You won $1 million in cash with Publishers Clearing House. Click the link to claim your prize now!!!\",\n",
    "    \"Reminder: your vehicle appointment is scheduled for Saturday at 7am with Hyundai Service. Reply YES to confirm.\"\n",
    "]\n",
    "\n",
    "# Clean, Vectorize, Predict\n",
    "my_clean = [clean_text(m) for m in my_messages]\n",
    "my_X = vectorizer.transform(my_clean)\n",
    "\n",
    "# Use the NB model\n",
    "preds = nb_model.predict(my_X)\n",
    "\n",
    "probs = None\n",
    "if hasattr(nb_model, \"predict_proba\"):\n",
    "    probs = nb_model.predict_proba(my_X)\n",
    "\n",
    "for i in range(len(my_messages)):\n",
    "    print(\"\\nMessage:\", my_messages[i])\n",
    "    print(\"Cleaned :\", my_clean[i])\n",
    "    print(\"Prediction:\", preds[i])\n",
    "\n",
    "    if probs is not None:\n",
    "        class_list = list(nb_model.classes_)\n",
    "        prob_list = probs[i].tolist()\n",
    "        prob_map = dict(zip(class_list, prob_list))\n",
    "        print(\"Probabilities:\", prob_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238e289-1334-4eb1-bf1e-f8f32081d0ac",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c711e1d-4a7a-46ad-a263-c88af9886ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) How well did your model perform?\n",
    "# The model got about 97% accuracy on the test set, which feels pretty good for a first\n",
    "# spam classifier using \"Bag of Words\". The classification report also shows strong precision\n",
    "# and recall, so it does a good job telling ham and spam apart from each other.\n",
    "\n",
    "# 2) Were any predictions surprising?\n",
    "# Yes. Some words that usually appear in spam can also come up in normal messages,\n",
    "# which can confuse the model it seemms sometimes. Also, short messages are harder to classify\n",
    "# because there is less text to analyze.\n",
    "\n",
    "# 3) What might help improve the model in the future?\n",
    "# - Use TF-IDF(Term Frequency–Inverse Document Frequency: looks at how important that word is!) instead of raw word counts, so very common words matter less.\n",
    "# - Try n-grams(lets the model look at small word phrases) to capture short phrases instead of just single words.\n",
    "# - Tuning parameters such as min_df and max_df to reduce noise.\n",
    "# - Use cross validation, so the score is not based on just one train/test split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
